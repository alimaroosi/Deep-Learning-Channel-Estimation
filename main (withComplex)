# example of calculation 2d convolutions
from this import d
from turtle import shapesize
from typing import Iterator
# from matplotlib.cbook import flatten
import math
import numpy as np
import keras as k
from numpy import asarray, dot, imag
from numpy import random
from keras.models import Sequential
from keras.layers import Conv2D, Flatten
from keras.layers import Dense
from keras.layers import Flatten
from keras.layers import Input
from keras.layers import Subtract
from keras.layers import add
from keras.models import Model
from keras.utils import plot_model
from torch import conv2d
import tensorflow as tf



def awgn(signal,snr):
    sigpower=np.sum(signal*np.conj(signal))
    sigpower=sigpower/signal.size
    noisepower=sigpower/(math.pow(10,snr/10))
    if(np.iscomplex(signal[0][0])):
        noise=math.sqrt(noisepower)/np.sqrt(2)* ( (np.random.randn(signal.shape[0],signal.shape[1]))+(np.random.randn(signal.shape[0],signal.shape[1])) *1j )
    else:
        noise=math.sqrt(noisepower)*(np.random.randn(signal.shape[0],signal.shape[1]))
    sig_noise=signal+noise
    return sig_noise

# define input data
data = [[0, 0, 0, 1.8, 1, 0, 0, 0],
        [0, 0, 0, 1, 1.2, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 0],
        [0, 0, 0, 1.5, 1, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 0],                   
        [0, 0, 0, 1.3, 1, 0, 0, 0],
        [0, 0, 0, 1, 1, 0, 0, 0],
        [0, 0, 0, 1, 1.6, 0, 0, 0]]
dim=100;
nsample=1000;
H=random.rand(dim,dim)+(random.rand(dim,dim))*1j
xin= 2*random.randint(0,2,size=(dim,nsample))-1 + (2*random.randint(0,2,size=(dim,nsample))-1 )*1j
ych_NoNoise=np.dot(H,xin)
snr=20
ych=awgn(ych_NoNoise,snr)



##### randomize or permutations samples
Ind=np.random.permutation(nsample)
ych_noSort=np.zeros(ych.shape).astype('complex128')
xin_noSort=np.zeros(xin.shape).astype('complex128')
for i, j1 in enumerate(Ind):
    ych_noSort[:,i]=ych[:,j1]
    xin_noSort[:,i]= xin[:,j1]

####### divide data test train
perc=0.7  ### percent of train data
nTrain= np.floor(perc*nsample).astype('uint16')
xTrain= ych_noSort[:,1:nTrain]
yTrain=xin_noSort[:,1:nTrain]
xTest= ych_noSort[:,nTrain+1:]
yTest= xin_noSort[:,nTrain+1:]


###accuracy with inverse
Hinv=np.linalg.inv(H)
yout_inv=np.dot(Hinv,xTest)
# accuracy_inv=np.sum(np.equal(np.round(yout_inv),yTest))/yTest.size
acc_R=np.sum(np.equal(np.sign(np.real(yout_inv)),np.real(yTest)))/yTest.size
acc_Im=np.sum(np.equal(np.sign(np.imag(yout_inv)),np.imag(yTest)))/yTest.size
accuracy_inv=(acc_R+acc_Im)/2
print('accuracy_inv= ',accuracy_inv )

############
##########################reshape for image input  (numsample,channel,row, clmn )
xTrain=np.transpose(xTrain).reshape(xTrain.shape[1],1,dim,1);
xTest=np.transpose(xTest).reshape(xTest.shape[1],1,dim,1);
yTrain=np.transpose(yTrain)
yTest=np.transpose(yTest)
#######
print(xin)
print(H)
print(H.shape)
data = asarray(data)
# # create model sequential
# model = Sequential()
# model.add(Conv2D(dim, (1,dim), input_shape=(1, dim, 1),activation='linear', name='layer1Conv'))
# model.add(Flatten( name='layer2Flat'))
# model.add(Dense(dim, activation='linear',name='layer3FC'))#'sigmoid'))  #'softmax'

Input_real=Input(shape=(1,dim,1)) #R1
Input_Im=Input(shape=(1,dim,1))#Im1

C2D_Re= Conv2D(dim,(1,dim),activation='linear', name='C2DReal') # R2
# cc=Conv2D(filters=64, kernel_size=(3,3), input_shape=(50, 50, 1),  activation="relu")
C2D_Im= Conv2D(dim,(1,dim),activation='linear',name='C2DIm') #Im2
# (R1+jIm1)*(R2+JIm2)= (R1*R2-Im1*Im2)+j(R1* Im2+Im1 *R2)
R1_R2=C2D_Re(Input_real)
R1_Im2=C2D_Im(Input_real)
Im1_R2=C2D_Re(Input_Im)
Im1_Im2=C2D_Im(Input_Im)
subtracted = Subtract()([R1_R2, Im1_Im2])
added=add([R1_Im2, Im1_R2])
subt_Flat=Flatten()(subtracted)
Add_Flat=Flatten()(added)
out_R=Dense(dim,activation='linear',name='FC_outR')(subt_Flat)
out_Im=Dense(dim,activation='linear',name='FC_outIm')(Add_Flat)

model=Model(inputs=[Input_real,Input_Im],outputs=[out_R,out_Im])

# summarize layers
print(model.summary())
# plot graph
plot_model(model, to_file='multilayer_perceptron_graph.png')

##################################################################
#############################Test with one sample #################
# xx=np.array([[  1],
# [14],
# [7]])
# ychxx= np.dot(H,xx)
# xTestxx=np.transpose(ychxx).reshape(1,1,dim,1);
# youtxx=model.predict([xTestxx,xTestxx])
#####################################################
#####################################################


#########Set weights
# #### prepare weights
Hinv=np.linalg.inv(H)
Hinv_T=np.transpose(Hinv)
print('Hinv_T')
print(Hinv_T)
##Setting new weights and biases
for i, layer in enumerate(model.layers):
    if layer.name=='C2DReal' :
        Weight = np.real(Hinv_T).reshape(layer.get_weights()[0].shape)
        layer.set_weights([Weight, np.zeros(layer.get_weights()[1].shape)])
    if layer.name=='C2DIm' :
        Weight = np.imag(Hinv_T).reshape(layer.get_weights()[0].shape)
        layer.set_weights([Weight, np.zeros(layer.get_weights()[1].shape)])
    if layer.name=='FC_outR' or  layer.name=='FC_outIm':
        Weight = np.eye(layer.get_weights()[0].shape[0],layer.get_weights()[0].shape[1])
        layer.set_weights([Weight, np.zeros(layer.get_weights()[1].shape)])

# for lys in model.layers:
#     print(lys.name,'/n')
#     print('wheight')
#     L=lys.get_weights()
#     try:
#         lys.get_weights()[0]
#         print("shape",lys.get_weights()[0].shape)
#         print(lys.get_weights()[0])
#         print('Bias')
#         print(lys.get_weights()[1])
#     except:
#         continue
##################################################################
#############################Test with one sample #################
# xx=np.array([[  1],
# [14],
# [7]])
# ychxx= np.dot(H,xx)
# xTestxx=np.transpose(ychxx).reshape(1,1,dim,1);
# youtxx=model.predict(xTestxx)
#####################################################
#####################################################
# Compile model
model.compile(optimizer='Adamax',loss='mse',metrics=['MeanSquaredError','accuracy']) ### nadam   0.001  #adam 0.02

    # SGD  0.01
    # RMSprop 0.03
    # Adam
    # Adadelta  0.5
    # Adagrad  0.17
    # Adamax 0.001
    # Nadam 0.001
    # Ftrl  0.8

##model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy']) ## for multi class  loss='categorical_crossentropy'
# This builds the model for the first time:

model.fit([np.real(xTrain),np.imag(xTrain)],[np.real(yTrain),np.imag(yTrain)],batch_size=dim, epochs=100)

for lys in model.layers:
    print(lys.name,'/n')
    print('wheight')
    L=lys.get_weights()
    try:
        lys.get_weights()[0]
        print("shape",lys.get_weights()[0].shape)
        print(lys.get_weights()[0])
        print('Bias')
        print(lys.get_weights()[1])
    except:
        continue


accuracyr = model.evaluate([np.real(xTrain),np.imag(xTrain)] ,[np.real(yTrain),np.imag(yTrain)], verbose=0)
yout1, yout2=model.predict([np.real(xTest),np.imag(xTest)])
acc_R=np.sum(np.equal(np.sign(yout1),np.real(yTest)))/yTest.size 
acc_Im=np.sum(np.equal(np.sign(yout2),np.imag(yTest)))/yTest.size 
accuracy=(acc_R+acc_Im)/2

print('accuracy=', accuracy)
print('accuracy_inv= ',accuracy_inv )

tt=0;
